{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\sorantes\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\externals\\joblib\\__init__.py:15: DeprecationWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "#--Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "#--global variables\n",
    "cv = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createModel(trainigSetPath):\n",
    "    df = pd.read_csv(trainigSetPath, encoding=\"latin-1\")\n",
    "    #------------------------------------\n",
    "    print(\"# of documents of the trainigSet: \",len(df))\n",
    "    #------------------------------------\n",
    "    x = df['message'].values\n",
    "    y = df['caseName'].values\n",
    "    x= cv.fit_transform(x) # Fit the Data\n",
    "    #Multinomial Naive Bayes Classifier\n",
    "    clf = MultinomialNB()\n",
    "    clf.fit(x, y)\n",
    "    \n",
    "    # alpha -> Additive Laplace smoothing parameter\n",
    "    # fit_prior ->Whether to learn class prior probabilities or not. If false, a uniform prior will be used\n",
    "    # class_prior->Prior probabilities of the classes. If specified the priors are not adjusted according to the data.\n",
    "    MultinomialNB(alpha=1.0, fit_prior=True, class_prior=None) \n",
    "    #save model\n",
    "    joblib.dump(clf, 'MNB_emailPrediction.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createTfidf(trainigSetPath):\n",
    "    df = pd.read_csv(trainigSetPath, encoding=\"latin-1\")\n",
    "    #------------------------------------\n",
    "    print(\"# of documents of the trainigSet: \",len(df))\n",
    "    #------------------------------------\n",
    "    docs = df['message'].values\n",
    "    labels = df['caseName'].values\n",
    "    word_count_vector=cv.fit_transform(docs)\n",
    "    word_count_vector.shape\n",
    "    tfidf_transformer=TfidfTransformer(smooth_idf=True,use_idf=True)\n",
    "    tfidf_transformer.fit(word_count_vector)\n",
    "    # print idf values\n",
    "    df_idf = pd.DataFrame(tfidf_transformer.idf_, index=cv.get_feature_names(),columns=[\"tf_idf_weights\"])\n",
    "    # sort ascending\n",
    "    df_idf.sort_values(by=['tf_idf_weights'])\n",
    "   \n",
    "    #print(df_idf)\n",
    "    \n",
    "    # count matrix\n",
    "    count_vector=cv.transform(docs)\n",
    "    # tf-idf scores\n",
    "    tf_idf_vector=tfidf_transformer.transform(count_vector)\n",
    "    feature_names = cv.get_feature_names()\n",
    " \n",
    "    #get tfidf vector for first document\n",
    "    first_document_vector=tf_idf_vector[0]\n",
    "\n",
    "    #print the scores\n",
    "    df = pd.DataFrame(first_document_vector.T.todense(), index=feature_names, columns=[\"tfidf\"])\n",
    "    df.sort_values(by=[\"tfidf\"],ascending=False)\n",
    "    print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadModel(modelPath, inputPath):\n",
    "    \n",
    "    NB_emailPrediction = open(modelPath,'rb')\n",
    "    clf = joblib.load(NB_emailPrediction)\n",
    "    input_df = pd.read_csv(inputPath, encoding=\"latin-1\")\n",
    "    #get input files and do a list\n",
    "    messageList =list(input_df['message'].values)\n",
    "    fromList =  list(input_df['from'].values)\n",
    "    #use model \n",
    "    verifier_Wcount = cv.transform(messageList)\n",
    "    predictions = clf.predict(verifier_Wcount)\n",
    "    #generate output\n",
    "    outputDict ={'from': fromList,'message':messageList,'predictions':predictions}\n",
    "    outputDf = pd.DataFrame.from_dict(outputDict)\n",
    "    outputDf.to_csv(path_or_buf=\"MLresult.csv\", sep=',',index=True)\n",
    "    \n",
    "    #------------------------------------\n",
    "    for i,j in zip(fromList,predictions):\n",
    "        print(i, \" ->\",j)\n",
    "    #------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of documents of the trainigSet:  10\n"
     ]
    }
   ],
   "source": [
    "createModel('CasesToStudy.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of documents of the trainigSet:  10\n",
      "                tfidf\n",
      "03           0.000000\n",
      "12           0.191620\n",
      "1200109816   0.000000\n",
      "123          0.191620\n",
      "12331        0.000000\n",
      "14           0.191620\n",
      "15           0.162895\n",
      "2019         0.000000\n",
      "22           0.000000\n",
      "2345151      0.191620\n",
      "234573       0.000000\n",
      "40           0.000000\n",
      "43           0.000000\n",
      "456          0.191620\n",
      "61           0.191620\n",
      "62           0.000000\n",
      "71           0.191620\n",
      "81           0.000000\n",
      "8934         0.000000\n",
      "address      0.000000\n",
      "all          0.000000\n",
      "amount       0.000000\n",
      "any          0.000000\n",
      "ap           0.000000\n",
      "at           0.000000\n",
      "bank         0.000000\n",
      "be           0.000000\n",
      "can          0.000000\n",
      "check        0.000000\n",
      "cleared      0.000000\n",
      "...               ...\n",
      "payables     0.000000\n",
      "paying       0.000000\n",
      "payment      0.000000\n",
      "payments     0.000000\n",
      "please       0.000000\n",
      "send         0.000000\n",
      "sending      0.000000\n",
      "shown        0.000000\n",
      "so           0.000000\n",
      "spreadsheet  0.000000\n",
      "systme       0.000000\n",
      "that         0.000000\n",
      "the          0.000000\n",
      "these        0.000000\n",
      "think        0.000000\n",
      "this         0.000000\n",
      "to           0.000000\n",
      "today        0.000000\n",
      "transaction  0.000000\n",
      "we           0.000000\n",
      "were         0.000000\n",
      "what         0.000000\n",
      "will         0.000000\n",
      "with         0.000000\n",
      "within       0.000000\n",
      "work         0.000000\n",
      "working      0.000000\n",
      "xxxxxxxxx    0.000000\n",
      "xxxxxxxxxxx  0.000000\n",
      "you          0.000000\n",
      "\n",
      "[103 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "#createTfidf('CasesToStudy.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Luis\t  -> p2p\n",
      "Pedro\t  -> Statements\n",
      "A  -> Dispute case and W-9 request\n",
      "B  -> Dispute case and W-9 request\n",
      "C  -> Dispute case and W-9 request\n",
      "D  -> Dispute case and W-9 request\n",
      "E  -> Dispute case and W-9 request\n",
      "F  -> p2p\n",
      "G  -> Dispute case and W-9 request\n"
     ]
    }
   ],
   "source": [
    "#loadModel('MNB_emailPrediction.pkl','input.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
